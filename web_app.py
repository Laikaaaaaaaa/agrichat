from flask import Flask, render_template, request, jsonify, send_from_directory
import os
import base64
import io
import re
import requests
import time
import random
import logging
from PIL import Image
import google.generativeai as genai
from dotenv import load_dotenv
from image_search import ImageSearchEngine
from modes import ModeManager
from model_config import get_model_config

# Thiáº¿t láº­p logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

HERE = os.path.dirname(os.path.abspath(__file__))

# Táº¡o Flask app
app = Flask(__name__, template_folder=HERE, static_folder=HERE)

class Api:
    def __init__(self):
        logging.info("Khá»Ÿi táº¡o AgriSense AI API...")
        load_dotenv()
        
        # Initialize Mode Manager
        logging.info("Khá»Ÿi táº¡o Mode Manager...")
        self.mode_manager = ModeManager()
        
        # Initialize Image Search Engine
        logging.info("Khá»Ÿi táº¡o Image Search Engine...")
        self.image_engine = ImageSearchEngine()
        
        # Initialize Short-term Memory (lÆ°u trá»¯ 10 cuá»™c há»™i thoáº¡i gáº§n nháº¥t)
        self.conversation_history = []
        self.max_history_length = 10
        logging.info("Khá»Ÿi táº¡o hoÃ n táº¥t!")

        # Setup API keys tá»« biáº¿n mÃ´i trÆ°á»ng
        raw_gemini_keys = os.getenv('GEMINI_API_KEYS')
        if raw_gemini_keys:
            self.gemini_api_keys = [key.strip() for key in re.split(r'[\s,;]+', raw_gemini_keys) if key.strip()]
        else:
            single_key = os.getenv('GEMINI_API_KEY', '').strip()
            self.gemini_api_keys = [single_key] if single_key else []

        if not self.gemini_api_keys:
            logging.warning("âš ï¸  KhÃ´ng tÃ¬m tháº¥y GEMINI_API_KEYS hoáº·c GEMINI_API_KEY. Vui lÃ²ng cáº¥u hÃ¬nh .env.")

        self.current_key_index = 0
        
        # Geography prompt for domain expertise
        self.geography_prompt = """
Báº¡n lÃ  chuyÃªn gia AI nÃ´ng nghiá»‡p thÃ´ng minh AgriSense AI vá»›i:
- Kiáº¿n thá»©c sÃ¢u vá» nÃ´ng nghiá»‡p, chÄƒn nuÃ´i, thá»§y sáº£n Viá»‡t Nam vÃ  quá»‘c táº¿
- Hiá»ƒu biáº¿t vá» cÃ´ng nghá»‡ smart farming, IoT, cáº£m biáº¿n nÃ´ng nghiá»‡p
- Kinh nghiá»‡m tÆ° váº¥n canh tÃ¡c, quáº£n lÃ½ dá»‹ch bá»‡nh, thá»i vá»¥
- Kháº£ nÄƒng phÃ¢n tÃ­ch hÃ¬nh áº£nh cÃ¢y trá»“ng, váº­t nuÃ´i, Ä‘áº¥t Ä‘ai

NHIá»†M Vá»¤ CHÃNH:
âœ… TÆ° váº¥n ká»¹ thuáº­t nÃ´ng nghiá»‡p chuyÃªn sÃ¢u
âœ… Nháº­n diá»‡n bá»‡nh táº­t cÃ¢y trá»“ng/váº­t nuÃ´i qua hÃ¬nh áº£nh  
âœ… ÄÆ°a ra giáº£i phÃ¡p canh tÃ¡c hiá»‡u quáº£
âœ… Cung cáº¥p thÃ´ng tin thá»‹ trÆ°á»ng nÃ´ng sáº£n
âœ… HÆ°á»›ng dáº«n sá»­ dá»¥ng cÃ´ng nghá»‡ thÃ´ng minh

PHONG CÃCH TRáº¢ Lá»œI:
- ChuyÃªn nghiá»‡p nhÆ°ng thÃ¢n thiá»‡n, dá»… hiá»ƒu
- Æ¯u tiÃªn giáº£i phÃ¡p thá»±c táº¿, kháº£ thi
- ÄÆ°a ra sá»‘ liá»‡u cá»¥ thá»ƒ khi cÃ³ thá»ƒ
- TÆ°Æ¡ng tÃ¡c báº±ng tiáº¿ng Viá»‡t tá»± nhiÃªn
"""
        
        # Log initial setup
        logging.info(f"Gemini API Keys: {len(self.gemini_api_keys)} khÃ³a")
        
        # Configure Gemini API with first key
        if self.gemini_api_keys:
            try:
                genai.configure(api_key=self.gemini_api_keys[self.current_key_index])
                logging.info(f"ÄÃ£ cáº¥u hÃ¬nh Gemini API vá»›i khÃ³a #{self.current_key_index + 1}")
            except Exception as e:
                logging.error(f"Lá»—i cáº¥u hÃ¬nh Gemini API: {e}")
        else:
            logging.error("âŒ KhÃ´ng cÃ³ API key Gemini Ä‘á»ƒ cáº¥u hÃ¬nh.")

    def generate_content_with_fallback(self, prompt, image_data=None):
        """Generate content with API key fallback"""
        max_attempts = len(self.gemini_api_keys)
        last_exception = None
        
        for attempt in range(max_attempts):
            try:
                model_config = get_model_config()
                model = genai.GenerativeModel(
                    model_name=model_config['model'],
                    generation_config=model_config['generation_config'],
                    safety_settings=model_config['safety_settings']
                )
                
                if image_data:
                    # Handle image + text input
                    content = [prompt, image_data]
                    response = model.generate_content(content)
                else:
                    # Handle text-only input
                    response = model.generate_content(prompt)
                
                return response
                
            except Exception as gen_error:
                last_exception = gen_error
                error_message = str(gen_error).lower()
                
                if any(quota_keyword in error_message for quota_keyword in 
                       ['quota', 'rate limit', 'too many requests', 'resource_exhausted']):
                    logging.warning(f"API key #{self.current_key_index + 1} háº¿t quota, chuyá»ƒn sang key tiáº¿p theo...")
                    if not self.get_next_gemini_key():
                        logging.error("Táº¥t cáº£ API keys Ä‘Ã£ háº¿t quota!")
                        break
                    continue
                else:
                    logging.error(f"Lá»—i khÃ´ng xá»­ lÃ½ Ä‘Æ°á»£c: {error_message}")
                    raise gen_error

        # If all keys failed, raise the last error with the last exception
        raise Exception(f"Táº¥t cáº£ {max_attempts} láº§n thá»­ API keys tháº¥t báº¡i. Lá»—i cuá»‘i: {last_exception}")

    def chat(self, message, image_data=None):
        """
        Main chat method for Flask API
        """
        try:
            # Kiá»ƒm tra lá»‡nh Ä‘áº·c biá»‡t Ä‘á»ƒ xÃ³a trÃ­ nhá»›
            if message.lower().strip() in ['xÃ³a lá»‹ch sá»­', 'reset', 'clear memory', 'xoa lich su']:
                return self.clear_conversation_history()
            
            # Kiá»ƒm tra lá»‡nh Ä‘á»ƒ xem lá»‹ch sá»­
            if message.lower().strip() in ['xem lá»‹ch sá»­', 'lá»‹ch sá»­', 'lich su', 'show history', 'history']:
                return self.show_conversation_history()
            
            # Láº¥y ngá»¯ cáº£nh tá»« lá»‹ch sá»­ há»™i thoáº¡i
            conversation_context = self.get_conversation_context()

            # Láº¥y system prompt theo cháº¿ Ä‘á»™ hiá»‡n táº¡i
            try:
                mode_system_prompt = self.mode_manager.get_system_prompt() or ''
            except Exception:
                mode_system_prompt = ''

            # Táº¡o prompt vá»›i ngá»¯ cáº£nh
            enhanced_prompt = f"""{mode_system_prompt}

{self.geography_prompt}

{conversation_context}

HÆ¯á»šNG DáºªN QUAN TRá»ŒNG:
- HÃ£y tham kháº£o lá»‹ch sá»­ há»™i thoáº¡i á»Ÿ trÃªn Ä‘á»ƒ hiá»ƒu ngá»¯ cáº£nh
- Náº¿u cÃ¢u há»i hiá»‡n táº¡i liÃªn quan Ä‘áº¿n cuá»™c há»™i thoáº¡i trÆ°á»›c, hÃ£y káº¿t ná»‘i thÃ´ng tin
- VÃ­ dá»¥: náº¿u trÆ°á»›c Ä‘Ã³ nÃ³i vá» "cÃ¢y xoÃ i" vÃ  bÃ¢y giá» há»i "chÃ³", hÃ£y tráº£ lá»i vá» chÃ³ nhÆ°ng cÃ³ thá»ƒ Ä‘á» cáº­p "khÃ¡c vá»›i cÃ¢y xoÃ i vá»«a nÃ³i..."
- Náº¿u khÃ´ng liÃªn quan, tráº£ lá»i bÃ¬nh thÆ°á»ng

CÃ¢u há»i hiá»‡n táº¡i: {message}"""
            
            # Generate AI response vá»›i ngá»¯ cáº£nh
            response = self.generate_content_with_fallback(enhanced_prompt, image_data)
            ai_response = response.text
            
            # LÆ°u cuá»™c há»™i thoáº¡i vÃ o trÃ­ nhá»›
            self.add_to_conversation_history(message, ai_response)
            
            return {"response": ai_response, "success": True}
            
        except Exception as e:
            error_response = f"Xin lá»—i, cÃ³ lá»—i xáº£y ra: {str(e)}"
            # Váº«n lÆ°u vÃ o lá»‹ch sá»­ Ä‘á»ƒ theo dÃµi
            self.add_to_conversation_history(message, error_response)
            return {"response": error_response, "success": False}

    def add_to_conversation_history(self, user_message, ai_response):
        """ThÃªm cuá»™c há»™i thoáº¡i vÃ o trÃ­ nhá»› ngáº¯n háº¡n"""
        conversation_item = {
            'timestamp': time.time(),
            'user': user_message,
            'ai': ai_response
        }
        
        self.conversation_history.append(conversation_item)
        
        # Giá»›i háº¡n sá»‘ lÆ°á»£ng cuá»™c há»™i thoáº¡i lÆ°u trá»¯
        if len(self.conversation_history) > self.max_history_length:
            self.conversation_history.pop(0)
        
        logging.info(f"ÄÃ£ lÆ°u cuá»™c há»™i thoáº¡i. Tá»•ng: {len(self.conversation_history)}")

    def get_conversation_context(self):
        """Láº¥y ngá»¯ cáº£nh tá»« lá»‹ch sá»­ há»™i thoáº¡i"""
        if not self.conversation_history:
            return "ÄÃ¢y lÃ  cuá»™c há»™i thoáº¡i Ä‘áº§u tiÃªn."
        
        context = "Lá»ŠCH Sá»¬ Há»˜I THOáº I Gáº¦N ÄÃ‚Y:\n"
        for i, conv in enumerate(self.conversation_history[-5:], 1):  # Chá»‰ láº¥y 5 cuá»™c há»™i thoáº¡i gáº§n nháº¥t
            context += f"\n[Há»™i thoáº¡i {i}]\n"
            context += f"NgÆ°á»i dÃ¹ng: {conv['user']}\n"
            context += f"AI: {conv['ai'][:200]}{'...' if len(conv['ai']) > 200 else ''}\n"
        
        return context

    def clear_conversation_history(self):
        """XÃ³a lá»‹ch sá»­ há»™i thoáº¡i"""
        self.conversation_history.clear()
        return "âœ… ÄÃ£ xÃ³a lá»‹ch sá»­ há»™i thoáº¡i. Báº¯t Ä‘áº§u cuá»™c trÃ² chuyá»‡n má»›i!"

    def show_conversation_history(self):
        """Hiá»ƒn thá»‹ lá»‹ch sá»­ há»™i thoáº¡i"""
        if not self.conversation_history:
            return "ğŸ“ ChÆ°a cÃ³ lá»‹ch sá»­ há»™i thoáº¡i nÃ o."
        
        history_text = f"ğŸ“š Lá»ŠCH Sá»¬ Há»˜I THOáº I ({len(self.conversation_history)} cuá»™c):\n\n"
        for i, conv in enumerate(self.conversation_history, 1):
            timestamp = time.strftime('%H:%M:%S', time.localtime(conv['timestamp']))
            history_text += f"[{i}] {timestamp}\n"
            history_text += f"ğŸ‘¤ Báº¡n: {conv['user']}\n"
            history_text += f"ğŸ¤– AI: {conv['ai'][:100]}{'...' if len(conv['ai']) > 100 else ''}\n\n"
        
        return history_text

    def get_next_gemini_key(self):
        """Chuyá»ƒn sang API key Gemini tiáº¿p theo khi gáº·p lá»—i"""
        if len(self.gemini_api_keys) <= 1:
            return False
            
        self.current_key_index = (self.current_key_index + 1) % len(self.gemini_api_keys)
        try:
            genai.configure(api_key=self.gemini_api_keys[self.current_key_index])
            logging.info(f"ÄÃ£ chuyá»ƒn sang Gemini API key #{self.current_key_index + 1}")
            return True
        except Exception as e:
            logging.error(f"Lá»—i khi chuyá»ƒn API key Gemini: {e}")
            return False

    def enhance_prompt_for_mode(self, prompt, image_data=None):
        """Enhance prompt based on current mode"""
        return self.mode_manager.enhance_prompt(prompt, image_data)

    def get_weather_info(self):
        """Láº¥y thÃ´ng tin thá»i tiáº¿t tá»« API"""
        try:
            # Simple weather API call - you can integrate with a weather service
            return {
                "success": True,
                "temp": "28",
                "condition": "Náº¯ng Ã­t mÃ¢y",
                "city": "Há»“ ChÃ­ Minh",
                "country": "Viá»‡t Nam"
            }
        except Exception as e:
            logging.error(f"Lá»—i láº¥y thÃ´ng tin thá»i tiáº¿t: {e}")
            return {"success": False, "message": "KhÃ´ng thá»ƒ láº¥y dá»¯ liá»‡u thá»i tiáº¿t"}

# Khá»Ÿi táº¡o API instance
api_instance = Api()

@app.route('/')
def index():
    """Trang chá»§"""
    return render_template('index.html')

@app.route('/static/<path:filename>')
def static_files(filename):
    """Serve static files"""
    return send_from_directory(HERE, filename)

@app.route('/js/<path:filename>')
def js_files(filename):
    """Serve JS files"""
    return send_from_directory(os.path.join(HERE, 'js'), filename)

@app.route('/templates/<path:filename>')
def template_files(filename):
    """Serve template files"""
    return send_from_directory(os.path.join(HERE, 'templates'), filename)

@app.route('/api/chat', methods=['POST'])
def chat():
    """API endpoint for chat"""
    try:
        data = request.json
        message = data.get('message', '')
        image_data = data.get('image_data')
        
        # Process message through API
        response = api_instance.chat(message, image_data)
        return jsonify(response)
    except Exception as e:
        logging.error(f"Lá»—i chat API: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/weather', methods=['GET'])
def weather():
    """API endpoint for weather"""
    try:
        weather_data = api_instance.get_weather_info()
        return jsonify(weather_data)
    except Exception as e:
        logging.error(f"Lá»—i weather API: {e}")
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    print("ğŸš€ Khá»Ÿi Ä‘á»™ng AgriSense AI Web Server...")
    print("ğŸ“¡ Server Ä‘ang cháº¡y táº¡i: http://localhost:5000")
    print("ğŸŒ Má»Ÿ trÃ¬nh duyá»‡t vÃ  truy cáº­p: http://localhost:5000")
    print("â­ Nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng server")
    
    app.run(
        host='127.0.0.1',
        port=5000,
        debug=True,
        use_reloader=False  # TrÃ¡nh restart khi debug
    )