"""
News Category Classifier using ML
Classifies articles into: Farming, Livestock, Technology, Weather, Market, Other
"""

import json
import logging
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
import pickle
import os

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Category keywords for rule-based fallback
CATEGORY_KEYWORDS = {
    'chƒÉn_nu√¥i': [
        'chƒÉn nu√¥i', 'gia s√∫c', 'gia c·∫ßm', 'ƒë√†n v·∫≠t nu√¥i', 'v·∫≠t nu√¥i', 'b√≤', 'l·ª£n', 'g√†', 'v·ªãt', 'c√°', 
        't√¥m', 'nu√¥i tr·ªìng', 'th·ª©c ƒÉn chƒÉn nu√¥i', 'vaccine gia s√∫c', 'b·ªánh gia s√∫c', 's·∫£n xu·∫•t chƒÉn nu√¥i',
        'ch·∫•t l∆∞·ª£ng th·ªãt', 's·ªØa', 'tr·ª©ng', 'b·∫£o v·ªá v·∫≠t nu√¥i', 'c·∫£i thi·ªán chƒÉn nu√¥i', 'k·ªπ thu·∫≠t chƒÉn nu√¥i',
        'trang tr·∫°i chƒÉn nu√¥i', 'nu√¥i d∆∞·ª°ng gia s√∫c', 'gi·ªëng gia s√∫c'
    ],
    'n√¥ng_nghi·ªáp': [
        'n√¥ng nghi·ªáp', 'c√¢y tr·ªìng', 'l√∫a', 'ng√¥', 'khoai', 'rau', 'qu·∫£', 'hoa', 'cacao', 'c√† ph√™',
        'tr·ªìng tr·ªçt', 'gi·ªëng c√¢y', 'ph√¢n b√≥n', 'ph√≤ng tr·ª´ s√¢u b·ªánh', 'm√°y n√¥ng nghi·ªáp', 't∆∞·ªõi ti√™u',
        'ƒë·∫•t n√¥ng nghi·ªáp', 'canh t√°c', 'v·ª• m∆∞a', 'v·ª• kh√¥', 'thu ho·∫°ch', 'gieo tr·ªìng', 'n√¥ng d√¢n',
        's·∫£n l∆∞·ª£ng l√∫a', 'c·∫£i thi·ªán nƒÉng su·∫•t', 'k·ªπ thu·∫≠t canh t√°c', 'trang tr·∫°i tr·ªìng tr·ªçt'
    ],
    'c√¥ng_ngh·ªá': [
        'c√¥ng ngh·ªá', 'AI', 'm√°y t√≠nh', '·ª©ng d·ª•ng', 'ph·∫ßn m·ªÅm', 'robot', 'IoT', 'c√¥ng ngh·ªá n√¥ng nghi·ªáp',
        'n√¥ng nghi·ªáp 4.0', 't·ª± ƒë·ªông h√≥a', 'tr√≠ tu·ªá nh√¢n t·∫°o', 'machine learning', 'smart farm',
        'c·∫£m bi·∫øn', 'd·ªØ li·ªáu', 'blockchain', 'c√¥ng ngh·ªá sinh h·ªçc', 'ph√¢n t√≠ch d·ªØ li·ªáu n√¥ng nghi·ªáp',
        '·ª©ng d·ª•ng c√¥ng ngh·ªá', 'h·ªá th·ªëng th√¥ng minh'
    ],
    'th·ªùi_ti·∫øt': [
        'th·ªùi ti·∫øt', 'm∆∞a', 'n·∫Øng', 'gi√≥', 'd·ª± b√°o', 'b√£o', 'l≈©', 'h·∫°n h√°n', 'nhi·ªát ƒë·ªô', 'ƒë·ªô ·∫©m',
        'kh√≠ h·∫≠u', 'thay ƒë·ªïi kh√≠ h·∫≠u', 'bi·∫øn ƒë·ªïi kh√≠ h·∫≠u', 'th·ªùi ti·∫øt n√¥ng nghi·ªáp', 'c·∫£nh b√°o th·ªùi ti·∫øt',
        'd·ª± b√°o m∆∞a', 'd·ª± b√°o n·∫Øng', 'ƒëi·ªÅu ki·ªán th·ªùi ti·∫øt'
    ],
    'th·ªã_tr∆∞·ªùng': [
        'th·ªã tr∆∞·ªùng', 'gi√°', 'bu√¥n b√°n', 'xu·∫•t kh·∫©u', 'nh·∫≠p kh·∫©u', 'cung c·∫ßu', 'kinh t·∫ø', 'l·ª£i nhu·∫≠n',
        'chi ph√≠', 'tƒÉng gi√°', 'gi·∫£m gi√°', 'doanh s·ªë', 'b√°n h√†ng', 'th∆∞∆°ng m·∫°i n√¥ng s·∫£n', 'n√¥ng s·∫£n',
        'gi√° n√¥ng s·∫£n', 'th·ªã gi√°', 'kho√° h√†ng', 'mua b√°n'
    ],
    'ch√≠nh_s√°ch': [
        'ch√≠nh s√°ch', 'ph√°p lu·∫≠t', 'h·ªó tr·ª£', 'ch∆∞∆°ng tr√¨nh', 'd·ª± √°n', 'quy·∫øt ƒë·ªãnh', 'ƒëi·ªÅu l·ªá',
        'h∆∞·ªõng d·∫´n', 'quy ƒë·ªãnh', 'y√™u c·∫ßu', 'ti√™u chu·∫©n', 'h·ª£p t√°c', 'h·ªôi nh·∫≠p', 'ngh·ªã ƒë·ªãnh',
        'lu·∫≠t l·ªá', 'c√¥ng b·ªë', 'th√¥ng t∆∞', 'c·∫£i c√°ch', 'ph√°t tri·ªÉn xanh', 'ph√°t th·∫£i', 'kh√≠ h·∫≠u',
        't√°i c∆° c·∫•u', 's·ªë h√≥a', 'qu·∫£n tr·ªã'
    ]
}

# Keywords to exclude or reduce weight for policy/regulation classification
POLICY_INDICATORS = [
    'ngh·ªã ƒë·ªãnh', 'lu·∫≠t', 'quy ƒë·ªãnh', 'th√¥ng t∆∞', 'quy·∫øt ƒë·ªãnh', 'c√¥ng b·ªë', 'c·∫£i c√°ch',
    'ph√°t th·∫£i', 'ph√°t tri·ªÉn xanh', 't√°i c∆° c·∫•u', 's·ªë h√≥a qu·∫£n tr·ªã', 'th·ªÉ ch·∫ø'
]

# Keywords to EXCLUDE - common false positives
EXCLUSION_KEYWORDS = {
    'chƒÉn_nu√¥i': ['n√¥ng nghi·ªáp chung', 'n√¥ng nghi·ªáp m√¥i tr∆∞·ªùng', 't√°i c∆° c·∫•u n√¥ng nghi·ªáp', 'ph√°t tri·ªÉn n√¥ng nghi·ªáp'],
    'n√¥ng_nghi·ªáp': ['chƒÉn nu√¥i gia s√∫c', 'nu√¥i v·∫≠t nu√¥i', 'th·ª©c ƒÉn chƒÉn nu√¥i'],
}

class NewsClassifier:
    """
    ML-based news classifier for agricultural articles
    """
    
    MODEL_PATH = 'news_classifier_model.pkl'
    
    def __init__(self):
        self.model = None
        self.vectorizer = None
        self.categories = list(CATEGORY_KEYWORDS.keys())
        self.load_or_create_model()
    
    def create_training_data(self):
        """Create training data from keywords"""
        X_train = []
        y_train = []
        
        # Create synthetic training data from keywords
        for category, keywords in CATEGORY_KEYWORDS.items():
            for keyword in keywords:
                # Create variations of keyword examples
                X_train.append(keyword)
                y_train.append(category)
                
                # Add some phrase variations
                if len(keyword.split()) == 1:
                    X_train.append(f"b√†i vi·∫øt v·ªÅ {keyword}")
                    y_train.append(category)
                    X_train.append(f"tin t·ª©c {keyword}")
                    y_train.append(category)
        
        return X_train, y_train
    
    def train_model(self):
        """Train the ML model"""
        try:
            logger.info('ü§ñ Training news classifier model...')
            
            X_train, y_train = self.create_training_data()
            
            # Create pipeline with TfidfVectorizer and MultinomialNB
            self.model = Pipeline([
                ('tfidf', TfidfVectorizer(
                    max_features=1000,
                    ngram_range=(1, 2),
                    min_df=1,
                    max_df=0.9
                )),
                ('clf', MultinomialNB())
            ])
            
            # Train model
            self.model.fit(X_train, y_train)
            
            # Save model
            self.save_model()
            logger.info('‚úÖ Model trained and saved successfully')
            
        except Exception as e:
            logger.error(f"‚ùå Error training model: {e}")
    
    def save_model(self):
        """Save trained model to file"""
        try:
            with open(self.MODEL_PATH, 'wb') as f:
                pickle.dump(self.model, f)
            logger.info(f'üíæ Model saved to {self.MODEL_PATH}')
        except Exception as e:
            logger.error(f"‚ùå Error saving model: {e}")
    
    def load_or_create_model(self):
        """Load existing model or create new one"""
        if os.path.exists(self.MODEL_PATH):
            try:
                with open(self.MODEL_PATH, 'rb') as f:
                    self.model = pickle.load(f)
                logger.info('‚úÖ Model loaded from disk')
                return
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error loading model: {e}")
        
        # Create new model if not found
        self.train_model()
    
    def _extract_ml_features(self, title, description, content):
        """Extract and combine features for ML prediction"""
        # Combine all text fields with importance weighting
        features = []
        
        # Title has highest importance (2x weight)
        if title:
            features.append(title + ' ' + title)
        
        # Description has medium importance (1.5x weight)
        if description:
            features.append(description + ' ' + description[:len(description)//2])
        
        # Content has normal weight
        if content:
            # Take first 500 chars of content
            features.append(content[:500])
        
        combined = ' '.join(features).lower()
        return combined
    
    def _rule_based_classification(self, title, description, content):
        """
        Improved rule-based classification with:
        - Policy detection (high priority)
        - Exclusion rules to prevent false positives
        - Content analysis (not just keyword matching)
        - Weighted scoring
        """
        combined_text = (title + ' ' + description + ' ' + content[:500]).lower()
        
        # Check for policy-related content first (high priority)
        policy_score = sum(1 for indicator in POLICY_INDICATORS if indicator in combined_text)
        if policy_score >= 2:
            logger.info("üìã Detected as POLICY based on policy indicators")
            return 'ch√≠nh_s√°ch', 0.9
        
        # Check for exclusions that would indicate another category
        for category, exclusions in EXCLUSION_KEYWORDS.items():
            for exclusion in exclusions:
                if exclusion in combined_text:
                    logger.info(f"‚ùå Exclusion match: '{exclusion}' ‚Üí NOT {category}")
        
        # Calculate scores for each category
        category_scores = {}
        
        for category, keywords in CATEGORY_KEYWORDS.items():
            score = 0
            matches = []
            
            for keyword in keywords:
                keyword_lower = keyword.lower()
                # Exact phrase match (higher weight)
                if keyword_lower in combined_text:
                    # Check if it's an exclusion
                    is_excluded = False
                    if category in EXCLUSION_KEYWORDS:
                        for exclusion in EXCLUSION_KEYWORDS[category]:
                            if exclusion in combined_text and keyword_lower not in exclusion:
                                is_excluded = True
                                break
                    
                    if not is_excluded:
                        score += 2  # Higher weight for exact matches
                        matches.append(keyword)
                # Partial word match (lower weight)
                elif any(word in combined_text for word in keyword_lower.split()):
                    score += 0.5
            
            if matches:
                logger.info(f"  {category}: score={score}, matches={matches[:3]}")
            
            category_scores[category] = score
        
        # Get category with highest score
        if category_scores and max(category_scores.values()) > 0:
            best_category = max(category_scores, key=category_scores.get)
            score = category_scores[best_category]
            
            # Normalize confidence to 0-1
            # Score of 2 = one exact match = 0.5 confidence
            # Score of 4+ = high confidence
            confidence = min(score / 4.0, 1.0)
            
            logger.info(f"üìã Rule-based result: {best_category} (score={score}, confidence={confidence:.2f})")
            return best_category, confidence
        
        logger.info("üìã No category matched, returning 'kh√°c'")
        return 'kh√°c', 0.0
    
    def classify(self, article=None, title='', description='', content=''):
        """
        Classify article into category
        Uses ML prediction with rule-based verification
        Can accept either:
        - article dict with 'title', 'description', 'source', 'content'
        - individual title, description, content parameters
        """
        try:
            # Handle both dict and parameter inputs
            if isinstance(article, dict):
                title = article.get('title', '')
                description = article.get('description', '')
                source = article.get('source', '')
                content = article.get('content', '')
                # Combine source into description for better context
                if source:
                    description = f"{source} {description}" if description else source
            
            # Ensure all values are strings
            title = str(title or '')
            description = str(description or '')
            content = str(content or '')
            
            # Prepare features
            combined_text = self._extract_ml_features(title, description, content)
            
            # Get ML prediction
            ml_prediction = None
            ml_confidence = 0.0
            
            if self.model and combined_text.strip():
                try:
                    predicted_category = self.model.predict([combined_text])[0]
                    probabilities = self.model.predict_proba([combined_text])[0]
                    ml_confidence = float(max(probabilities))
                    ml_prediction = predicted_category
                    
                    logger.info(f"ü§ñ ML Prediction: {predicted_category} (confidence: {ml_confidence:.2f})")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è ML prediction error: {e}")
            
            # Get rule-based classification
            rule_category, rule_confidence = self._rule_based_classification(
                title, description, content
            )
            
            logger.info(f"üìã Rule-based: {rule_category} (confidence: {rule_confidence:.2f})")
            
            # Combine predictions: prefer ML if high confidence, else use rule-based
            if ml_confidence >= 0.4:
                final_category = ml_prediction
                final_confidence = ml_confidence
                method = 'ML'
            elif rule_confidence > 0:
                final_category = rule_category
                final_confidence = rule_confidence
                method = 'Rule-based'
            else:
                final_category = 'kh√°c'
                final_confidence = 0.0
                method = 'Default'
            
            # Map internal category names to display names
            category_display = {
                'chƒÉn_nu√¥i': 'ChƒÉn nu√¥i',
                'n√¥ng_nghi·ªáp': 'N√¥ng nghi·ªáp',
                'c√¥ng_ngh·ªá': 'C√¥ng ngh·ªá',
                'th·ªùi_ti·∫øt': 'Th·ªùi ti·∫øt',
                'th·ªã_tr∆∞·ªùng': 'Th·ªã tr∆∞·ªùng',
                'ch√≠nh_s√°ch': 'Ch√≠nh s√°ch',
                'kh√°c': 'Kh√°c'
            }
            
            result = {
                'category': final_category,
                'display_category': category_display.get(final_category, final_category),
                'confidence': round(final_confidence, 2),
                'method': method,
                'ml_prediction': ml_prediction,
                'ml_confidence': round(ml_confidence, 2),
                'rule_prediction': rule_category,
                'rule_confidence': round(rule_confidence, 2)
            }
            
            logger.info(f"‚úÖ Final classification: {result['display_category']} ({method}, {final_confidence:.2f})")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Classification error: {e}")
            return {
                'category': 'kh√°c',
                'display_category': 'Kh√°c',
                'confidence': 0.0,
                'error': str(e)
            }
    
    def classify_batch(self, articles):
        """
        Classify multiple articles
        articles: list of dicts with 'title', 'description', 'content'
        """
        results = []
        for article in articles:
            result = self.classify(
                title=article.get('title', ''),
                description=article.get('description', ''),
                content=article.get('content', '')
            )
            results.append({
                **article,
                'classification': result
            })
        
        return results


# Global classifier instance
_classifier = None

def get_classifier():
    """Get or create global classifier instance"""
    global _classifier
    if _classifier is None:
        _classifier = NewsClassifier()
    return _classifier

def classify_article(title='', description='', content=''):
    """
    Convenience function to classify a single article
    """
    classifier = get_classifier()
    return classifier.classify(title, description, content)

def classify_articles(articles):
    """
    Convenience function to classify multiple articles
    """
    classifier = get_classifier()
    return classifier.classify_batch(articles)
