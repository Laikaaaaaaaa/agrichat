"""
News Category Classifier using ML
Classifies articles into: Farming, Livestock, Technology, Weather, Market, Other
"""

import json
import logging
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
import pickle
import os

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Category keywords for rule-based fallback
CATEGORY_KEYWORDS = {
    'chƒÉn_nu√¥i': [
        'chƒÉn nu√¥i', 'gia s√∫c', 'gia c·∫ßm', 'ƒë√†n v·∫≠t nu√¥i', 'v·∫≠t nu√¥i', 'b√≤', 'l·ª£n', 'g√†', 'v·ªãt', 'c√°', 
        't√¥m', 'nu√¥i tr·ªìng', 'th·ª©c ƒÉn chƒÉn nu√¥i', 'vaccine', 'b·ªánh gia s√∫c', 's·∫£n xu·∫•t chƒÉn nu√¥i',
        'ch·∫•t l∆∞·ª£ng th·ªãt', 's·ªØa', 'tr·ª©ng', 'b·∫£o v·ªá v·∫≠t nu√¥i', 'c·∫£i thi·ªán chƒÉn nu√¥i', 'k·ªπ thu·∫≠t chƒÉn nu√¥i'
    ],
    'n√¥ng_nghi·ªáp': [
        'n√¥ng nghi·ªáp', 'c√¢y tr·ªìng', 'l√∫a', 'ng√¥', 'khoai', 'rau', 'qu·∫£', 'hoa', 'cacao', 'c√† ph√™',
        'tr·ªìng tr·ªçt', 'gi·ªëng c√¢y', 'ph√¢n b√≥n', 'ph√≤ng tr·ª´ s√¢u b·ªánh', 'm√°y n√¥ng nghi·ªáp', 't∆∞·ªõi ti√™u',
        'ƒë·∫•t n√¥ng nghi·ªáp', 'canh t√°c', 'v·ª• m∆∞a', 'v·ª• kh√¥', 'thu ho·∫°ch', 'gieo tr·ªìng', 'n√¥ng d√¢n',
        's·∫£n l∆∞·ª£ng l√∫a', 'c·∫£i thi·ªán nƒÉng su·∫•t', 'k·ªπ thu·∫≠t canh t√°c'
    ],
    'c√¥ng_ngh·ªá': [
        'c√¥ng ngh·ªá', 'AI', 'm√°y t√≠nh', '·ª©ng d·ª•ng', 'ph·∫ßn m·ªÅm', 'robot', 'IoT', 'c√¥ng ngh·ªá n√¥ng nghi·ªáp',
        'n√¥ng nghi·ªáp 4.0', 't·ª± ƒë·ªông h√≥a', 'tr√≠ tu·ªá nh√¢n t·∫°o', 'machine learning', 'smart farm',
        'c·∫£m bi·∫øn', 'd·ªØ li·ªáu', 'blockchain', 'c√¥ng ngh·ªá sinh h·ªçc', 'ph√¢n t√≠ch d·ªØ li·ªáu n√¥ng nghi·ªáp'
    ],
    'th·ªùi_ti·∫øt': [
        'th·ªùi ti·∫øt', 'm∆∞a', 'n·∫Øng', 'gi√≥', 'd·ª± b√°o', 'b√£o', 'l≈©', 'h·∫°n h√°n', 'nhi·ªát ƒë·ªô', 'ƒë·ªô ·∫©m',
        'kh√≠ h·∫≠u', 'thay ƒë·ªïi kh√≠ h·∫≠u', 'bi·∫øn ƒë·ªïi kh√≠ h·∫≠u', 'th·ªùi ti·∫øt n√¥ng nghi·ªáp', 'c·∫£nh b√°o th·ªùi ti·∫øt'
    ],
    'th·ªã_tr∆∞·ªùng': [
        'th·ªã tr∆∞·ªùng', 'gi√°', 'bu√¥n b√°n', 'xu·∫•t kh·∫©u', 'nh·∫≠p kh·∫©u', 'cung c·∫ßu', 'kinh t·∫ø', 'l·ª£i nhu·∫≠n',
        'chi ph√≠', 'tƒÉng gi√°', 'gi·∫£m gi√°', 'doanh s·ªë', 'b√°n h√†ng', 'th∆∞∆°ng m·∫°i n√¥ng s·∫£n', 'n√¥ng s·∫£n'
    ],
    'ch√≠nh_s√°ch': [
        'ch√≠nh s√°ch', 'ph√°p lu·∫≠t', 'h·ªó tr·ª£', 'ch∆∞∆°ng tr√¨nh', 'd·ª± √°n', 'quy·∫øt ƒë·ªãnh', 'ƒëi·ªÅu l·ªá',
        'h∆∞·ªõng d·∫´n', 'quy ƒë·ªãnh', 'y√™u c·∫ßu', 'ti√™u chu·∫©n', 'h·ª£p t√°c', 'h·ªôi nh·∫≠p'
    ]
}

class NewsClassifier:
    """
    ML-based news classifier for agricultural articles
    """
    
    MODEL_PATH = 'news_classifier_model.pkl'
    
    def __init__(self):
        self.model = None
        self.vectorizer = None
        self.categories = list(CATEGORY_KEYWORDS.keys())
        self.load_or_create_model()
    
    def create_training_data(self):
        """Create training data from keywords"""
        X_train = []
        y_train = []
        
        # Create synthetic training data from keywords
        for category, keywords in CATEGORY_KEYWORDS.items():
            for keyword in keywords:
                # Create variations of keyword examples
                X_train.append(keyword)
                y_train.append(category)
                
                # Add some phrase variations
                if len(keyword.split()) == 1:
                    X_train.append(f"b√†i vi·∫øt v·ªÅ {keyword}")
                    y_train.append(category)
                    X_train.append(f"tin t·ª©c {keyword}")
                    y_train.append(category)
        
        return X_train, y_train
    
    def train_model(self):
        """Train the ML model"""
        try:
            logger.info('ü§ñ Training news classifier model...')
            
            X_train, y_train = self.create_training_data()
            
            # Create pipeline with TfidfVectorizer and MultinomialNB
            self.model = Pipeline([
                ('tfidf', TfidfVectorizer(
                    max_features=1000,
                    ngram_range=(1, 2),
                    min_df=1,
                    max_df=0.9
                )),
                ('clf', MultinomialNB())
            ])
            
            # Train model
            self.model.fit(X_train, y_train)
            
            # Save model
            self.save_model()
            logger.info('‚úÖ Model trained and saved successfully')
            
        except Exception as e:
            logger.error(f"‚ùå Error training model: {e}")
    
    def save_model(self):
        """Save trained model to file"""
        try:
            with open(self.MODEL_PATH, 'wb') as f:
                pickle.dump(self.model, f)
            logger.info(f'üíæ Model saved to {self.MODEL_PATH}')
        except Exception as e:
            logger.error(f"‚ùå Error saving model: {e}")
    
    def load_or_create_model(self):
        """Load existing model or create new one"""
        if os.path.exists(self.MODEL_PATH):
            try:
                with open(self.MODEL_PATH, 'rb') as f:
                    self.model = pickle.load(f)
                logger.info('‚úÖ Model loaded from disk')
                return
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error loading model: {e}")
        
        # Create new model if not found
        self.train_model()
    
    def _extract_ml_features(self, title, description, content):
        """Extract and combine features for ML prediction"""
        # Combine all text fields with importance weighting
        features = []
        
        # Title has highest importance (2x weight)
        if title:
            features.append(title + ' ' + title)
        
        # Description has medium importance (1.5x weight)
        if description:
            features.append(description + ' ' + description[:len(description)//2])
        
        # Content has normal weight
        if content:
            # Take first 500 chars of content
            features.append(content[:500])
        
        combined = ' '.join(features).lower()
        return combined
    
    def _rule_based_classification(self, title, description, content):
        """
        Rule-based classification as fallback/verification
        Returns category and confidence score
        """
        combined_text = (title + ' ' + description + ' ' + content[:300]).lower()
        
        category_scores = {}
        
        for category, keywords in CATEGORY_KEYWORDS.items():
            score = 0
            for keyword in keywords:
                # Check for exact keyword match with word boundaries
                if keyword.lower() in combined_text:
                    score += 1
                # Check for partial matches
                elif any(word in combined_text for word in keyword.lower().split()):
                    score += 0.5
            
            category_scores[category] = score
        
        # Get category with highest score
        if category_scores and max(category_scores.values()) > 0:
            best_category = max(category_scores, key=category_scores.get)
            confidence = min(category_scores[best_category] / 5.0, 1.0)  # Normalize to 0-1
            return best_category, confidence
        
        return 'kh√°c', 0.0
    
    def classify(self, title='', description='', content=''):
        """
        Classify article into category
        Uses ML prediction with rule-based verification
        """
        try:
            # Prepare features
            combined_text = self._extract_ml_features(title, description, content)
            
            # Get ML prediction
            ml_prediction = None
            ml_confidence = 0.0
            
            if self.model and combined_text.strip():
                try:
                    predicted_category = self.model.predict([combined_text])[0]
                    probabilities = self.model.predict_proba([combined_text])[0]
                    ml_confidence = float(max(probabilities))
                    ml_prediction = predicted_category
                    
                    logger.info(f"ü§ñ ML Prediction: {predicted_category} (confidence: {ml_confidence:.2f})")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è ML prediction error: {e}")
            
            # Get rule-based classification
            rule_category, rule_confidence = self._rule_based_classification(
                title, description, content
            )
            
            logger.info(f"üìã Rule-based: {rule_category} (confidence: {rule_confidence:.2f})")
            
            # Combine predictions: prefer ML if high confidence, else use rule-based
            if ml_confidence >= 0.4:
                final_category = ml_prediction
                final_confidence = ml_confidence
                method = 'ML'
            elif rule_confidence > 0:
                final_category = rule_category
                final_confidence = rule_confidence
                method = 'Rule-based'
            else:
                final_category = 'kh√°c'
                final_confidence = 0.0
                method = 'Default'
            
            # Map internal category names to display names
            category_display = {
                'chƒÉn_nu√¥i': 'ChƒÉn nu√¥i',
                'n√¥ng_nghi·ªáp': 'N√¥ng nghi·ªáp',
                'c√¥ng_ngh·ªá': 'C√¥ng ngh·ªá',
                'th·ªùi_ti·∫øt': 'Th·ªùi ti·∫øt',
                'th·ªã_tr∆∞·ªùng': 'Th·ªã tr∆∞·ªùng',
                'ch√≠nh_s√°ch': 'Ch√≠nh s√°ch',
                'kh√°c': 'Kh√°c'
            }
            
            result = {
                'category': final_category,
                'display_category': category_display.get(final_category, final_category),
                'confidence': round(final_confidence, 2),
                'method': method,
                'ml_prediction': ml_prediction,
                'ml_confidence': round(ml_confidence, 2),
                'rule_prediction': rule_category,
                'rule_confidence': round(rule_confidence, 2)
            }
            
            logger.info(f"‚úÖ Final classification: {result['display_category']} ({method}, {final_confidence:.2f})")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Classification error: {e}")
            return {
                'category': 'kh√°c',
                'display_category': 'Kh√°c',
                'confidence': 0.0,
                'error': str(e)
            }
    
    def classify_batch(self, articles):
        """
        Classify multiple articles
        articles: list of dicts with 'title', 'description', 'content'
        """
        results = []
        for article in articles:
            result = self.classify(
                title=article.get('title', ''),
                description=article.get('description', ''),
                content=article.get('content', '')
            )
            results.append({
                **article,
                'classification': result
            })
        
        return results


# Global classifier instance
_classifier = None

def get_classifier():
    """Get or create global classifier instance"""
    global _classifier
    if _classifier is None:
        _classifier = NewsClassifier()
    return _classifier

def classify_article(title='', description='', content=''):
    """
    Convenience function to classify a single article
    """
    classifier = get_classifier()
    return classifier.classify(title, description, content)

def classify_articles(articles):
    """
    Convenience function to classify multiple articles
    """
    classifier = get_classifier()
    return classifier.classify_batch(articles)
